图像完全装入目标区域，此时目标区域会产生部分空白，用模型要求的颜色来填充，若无特殊要求，则可用白色或黑色填充。这种场景的图像变换与通过JavaScript实现background-size: contain的思路是一致的，对此内容熟悉的读者可跳过这部分。
```javascript
/**
 * 以contain的方式缩放图像至目标尺寸并居中
 * @param image image DOM对象
 * @param targetSize
 * @param targetSize.targetWidth 目标宽度
 * @param targetSize.targetHeight 目标高度
 * @param targetContext 处理图像的canvas上下文
 * @return {Array} 缩放后的图像像素数据
 */
fitWithContain(image, targetSize, targetContext) {
    // 原始图像宽和高
    const width = image.width;
    const height = image.height;
    // 目标区域宽和高
    const { targetWidth, targetHeight } = targetSize;

    // 计算目标区域与图像区域的宽高比
    const scale = targetWidth / targetHeight * height / width;

    let sw = targetWidth;
    let sh = targetHeight;
    let x = 0;
    let y = 0;

    if (scale > 1) {
        // 目标区域的宽高比较大，将图像宽度缩放至目标宽度
        sh = Math.round(height * sw / width);
        y = (sh - targetHeight) / 2;
    } else {
        // 图像的宽高比较大，将图像高度缩放至目标高度
        sw = Math.round(sh * width / height);
        x = (sw - targetWidth) / 2;
    }

    // 绘制图像
    targetContext.canvas.width = sw;
    targetContext.canvas.height = sh;
    targetContext.drawImage(image, 0, 0, sw, sh);

    // 读取目标区域大小的图像信息
    const data = targetContext.getImageData(x, y, targetWidth, targetHeight);
    return data;
}
```
2. **保留输入图像有效信息的宽高比**
保留输入图像有效信息的宽高比，可类比于background-size: cover的实现，尽可能地缩放图像并保持宽高比，使图像的全部宽或高覆盖目标区域。当目标区域和图像宽高比不同时，图像的上、下或左、右部分会被裁剪，部分图像信息会丢失，代码实现如下。
```javascript
/**
 * 以cover的方式缩放图像至目标尺寸并居中
 * @param image image DOM对象
 * @param targetSize
 * @param targetSize.targetWidth 目标宽度
 * @param targetSize.targetHeight 目标高度
 * @param targetContext 处理图像的canvas上下文
 * @param fillColor 填充色值
 * @return {Array} 缩放后的图像像素数据
 */
fitWithCover(image, targetSize, targetContext, fillColor) {
    // 原始图像的宽和高
    const width = image.width;
    const height = image.height;
    // 目标区域的宽和高
    const { targetWidth, targetHeight } = targetSize;
    this.targetContext.canvas.width = targetWidth;
    this.targetContext.canvas.height = targetHeight;
    this.targetContext.fillStyle = fillColor || '#fff';
    this.targetContext.fillRect(0, 0, targetHeight, targetWidth);

    // 计算目标区域与图像区域的宽高比
    const scale = targetWidth / targetHeight * height / width;

    // 缩放后的宽和高
    let sw = targetWidth;
    let sh = targetHeight;
    let x = 0;
    let y = 0;
    if (scale > 1) {
        // 目标区域的宽高比较大，将图像高度缩放至目标高度
        sw = Math.round(width * sh / height);
        x = Math.floor((targetWidth - sw) / 2);
    } else {
        // 图像的宽高比较大，将图像宽度缩放至目标宽度
        sh = Math.round(height * sw / width);
        y = Math.floor((targetHeight - sh) / 2);
    }

    targetContext.drawImage(image, x, y, sw, sh);
    // 读取目标区域大小的图像信息
    const data = targetContext.getImageData(0, 0, targetWidth, targetHeight);
    return data;
}
```
3. **拉伸图像宽和高以适应目标区域**
拉伸图像宽和高以适应目标区域，可类比于background-size直接指定宽和高的情况，按照目标区域的宽和高对图像进行伸缩处理。当目标区域和图像宽高比不同时，会改变图像的宽高比，而非依靠填充和裁剪，代码实现如下。
```javascript
/**
 * 以cover的方式缩放图像至目标尺寸并居中
 * @param image image DOM对象
 * @param targetSize
 * @param targetSize.targetWidth 目标宽度
 * @param targetSize.targetHeight 目标高度
 * @param targetContext 处理图像的canvas上下文
 * @return {Array} 缩放后的图像像素数据
 */
resize(image, targetSize, targetContext) {
    // 原始图像宽和高
    const width = image.width;
    const height = image.height;
    // 目标区域的宽和高
    const { targetWidth, targetHeight } = targetSize;

    // 绘制图像
    this.targetContext.canvas.width = targetWidth;
    this.targetContext.canvas.height = targetHeight;
    targetContext.drawImage(image, 0, 0, width, height);
    // 读取目标区域大小的图像信息
    const data = targetContext.getImageData(0, 0, targetWidth, targetHeight);
    return data;
}
```

### 6.2 模型后处理
模型推理后输出的结果是有特定模式的数据，一般会以数组的形式组织。基于推理结果，要进一步处理才会变得有意义，供AI应用使用。
不同模型的后处理方法也不同，下面从目标分类、目标框选和目标分割来介绍。

#### 6.2.1 目标分类
如第4章介绍的1000种物品分类的应用，使用Mobilenet模型对物品进行分类，推理结果是长度为1000的数组。数组中的每个值是预测输入图像属于每个物品类别的概率。如图6-1所示，获取推理结果中最大值所在的数组索引，根据索引从分类Map中找到对应的物品分类，这个分类就是输入的图像最可能属于的物品类别。

#### 6.2.2 目标框选
从图像中框选出特定目标是很常见的应用场景，如使用yolo模型框选出图像中的白猫、猫和动物等，可能是单目标或多目标的框选。这类场景的推理结果一般是一系列的框的坐标及其对应的置信度。可根据应用需要，结合置信度和框的相对面积，获取一个或多个框的位置。如图6-2所示，识别出图像中的人脸位置，可将置信度最高的框坐标作为单目标结果，也可将推理结果按照置信度从高到低排序，取前10个结果中面积最大的5个框作为多目标结果。

#### 6.2.3 目标分割
将目标从图像的背景中分离出来，如第4章介绍的人像分割应用。推理后会得到输入图像每个像素点的透明度，该值已被归一化为0~1。由于每个单色通道值的取值范围为0~255，因此需要将推理结果乘以255，反归一化为0~255，作为输入图像的alpha通道值，保存成RGBA格式的图像。这张图像非人像的部分的透明度接近于0，如图6-3所示。将其作为前景，与任意背景图叠加，都会达到背景替换的效果。

### 6.3 总结
本章介绍了推理前后的两个衔接环节——模型前处理和模型后处理。
模型前处理环节是对输入模型的数据进行处理。输入的数据可能是用户上传的一张图像，也可能是用户摄像机的视频流中的每张图像，还可能是前一个模型的输出结果。可从媒体数据中直接通过canvas获取到像素数据，也可作为在WebGL上下文中的texture进一步处理。不同模型对输入数据的处理方式不同，一般包括对输入图像进行伸缩、裁剪、填充变换、数据排布转换、取均值和归一化等处理。
模型后处理环节是对推理结果的进一步处理。推理结果可能是一堆看起来无意义的数据，针对不同模型使用不同的后处理方法，处理后再给AI应用使用。例如，目标分类模型需要从推理结果中计算出最大值所在的数组索引，根据索引从分类Map中找到对应的物品分类，作为输入图像最大概率的物品类别；目标框选模型需要对推理结果中的阈值排序获得置信度最高的框，进一步结合框的面积计算，取得置信度相对高且面积较大的框；目标分割模型需要推理出输入图像的透明度，转换为alpha通道值，并隐藏输入图像的非主体部分。 
