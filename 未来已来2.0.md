一个很重要的步骤是微调（Fine-Tune），即需要重新提供大量的例子并调节模型，“教”模型输出更好的结果。

这种流程限制了大语言模型在不同领域之间的泛化能力，这种情况在GPT-3出现之后发生了变化，研究人员只需要提供少量的范例，且范例之间只要有正确的逻辑关系，则GPT-3就会给出相应合理的结果，而且大概率是正确的。不过，这一过程如此复杂，以至于不可梳理出明确的因果关系来解释模型推理的过程。

前文一直强调的“涌现”现象，让大语言模型可能带来不可预测的行为和结果，这也是为什么在使用GPT时要谨慎对待输出的结果。

### 12.2 前端和大语言模型

对程序员来说，大语言模型带来的变革最直接的是“写代码的效率更高了”，在各种相关工具中，最熟悉的莫过于GitHub Copilot。

据统计，在GitHub Copilot上线不到两年内，就已经帮助100多万名开发者编写了46%的代码，提高了55%的编码速度。而对于最新版本的Copilot X，则覆盖了编程方面的更多功能，包括文档、单元测试等。

曾几何时，我们挂在嘴边的“Talk is cheap, Show me the code”变成了过去式，“Talking is as important as coding”的时代到来了。

在新时代下，前端（可以扩展到任何与编程相关的岗位）开发必然要进行一场“范式”革命，从面向经验和文档的开发方式，迁移至结合大语言模型的“联合开发”模式。

随着GPT等模型能力的不断提升，可以预见的是，大语言模型会从帮助开发者提升效率跃迁为帮助开发者端到端地解决编程问题。

**12.2.1 提示语是一切的核心**

在介绍如何利用大语言模型解决实际问题之前，我们需要明确一个观点：提示语是一切的核心！

我们和GPT等大语言模型之间是“命令者”和“执行人”之间的关系。GPT能否按照需求产出相应的代码和文档，取决于提示语的质量。

事实上，因为并不是所有人都具备给出高质量提示语的能力，所以围绕提示语，有很多公司和团队已经在尝试通过工具和平台来增强提示语，主要包含两方面的增强：优化提示语和能力扩展。

1. **优化提示语**

针对提示语本身的优化是对一个人“语言能力”和“技术理解力”的双重考验，在GitHub上获得数万条赞的仓库“Awesome-Chatgpt-Prompts”给出了在各个领域（学术论文、内容创作、广告文案等）中优秀的提示语范例。

例如，我们首先可以通过以下提示语让ChatGPT化身为一个Linux终端。

I want you to act as a Linux terminal. I will type commands and you will reply with what the terminal should show. I want you to only reply with the terminal output inside one unique code block, and nothing else. do not write explanations. do not type commands unless I instruct you to do so. When I need to tell you something in English, I will do so by putting text inside curly brackets {like this}. My first command is pwd.（我想让你扮演Linux终端，我会输入命令，你会回复终端应该显示什么。我希望你仅仅在唯一的代码块内回复终端输出，不要其他的任何东西，不要写解释。除非我指示你这样做，否则不要输入命令。当我需要用英语告诉你时，我会用花括号将文本包起来，如{}。我的第一个命令是pwd。）

接着我们就可以在多轮会话中与ChatGPT进行交流。

除了时刻保持给出高质量的提示语的意识，有公司还尝试把优化提示语的过程自动化。

例如，如果要借助DALL-E 2生成一张图像，需求是提供一张“a cute magical flying dog（一只可爱的神奇飞行狗）”图像，那么Jina AI公司的PromptPerfect可以帮助优化提示语，从而生成一张可爱的神奇飞行狗的图像。

A magical golden retriever puppy flying in midair, surrounded by a glowing aura of pink and purple fairy dust. The puppy is looking up at the camera with bright eyes full of wonder and amazement.（一只神奇的金毛寻回犬在半空中飞行，周围是粉红色和紫色的精灵尘埃。小狗抬头看着摄像机，明亮的眼睛充满了好奇和惊讶。）

提示：DALL-E 2是OpenAI开发的第二代DALL-E系统。DALL-E的原始版本是一种先进的AI图像生成模型，能够通过文本描述生成对应的图像。它融合了自然语言处理和计算机视觉技术，实现了从文本到图像的转换。DALL-E基于GPT-3模型进行训练，因此具备生成准确、有趣和富有创意的图像的能力。


2. **能力扩展**

ChatGPT推出的插件能力是对提示语进行能力扩展的绝佳代表。事实上，能力扩展不仅可以优化提示语，还可以优化模型回复的内容。

在与ChatGPT聊天时，可以通过指定插件让返回的内容针对插件的功能进行结构化的输出，从而满足特定领域的功能需求。

这些插件的功能覆盖了旅游、购物和数据分析等领域。

除了插件，fixie.ai提供的针对大语言模型的代理思路也值得关注。实际上，代理是另一种类型的插件，它可以自动地将用户的提示语“路由”到对应的代理中，并调用封装好的云函数来完成某个任务。

![image](https://github.com/user-attachments/assets/cd9b366f-da10-444c-9723-730cc68a6c66)


此外，2023年3月诞生的Auto-GPT也为GPT能力的延伸提供了新的思路。用户可以通过交互式对话同Auto-GPT中设定的AI角色进行沟通，指定任务并明确目标。Auto-GPT会将任务拆解，并能够从互联网中获取资源，将返回的数据结构化。例如，访问互联网、写文件等功能，Auto-GPT以command（命令）的方式封装，调用何种command先由GPT-4等大语言模型分析给出，再由用户来决策是否接受command的调用。

经过多轮交互，Auto-GPT可以整合大语言模型的能力和外接资源，完成用户的任务。

![image](https://github.com/user-attachments/assets/2acf2d33-1df5-490d-a243-353ba0ed4459)
图12-11 Auto-GPT以command的方式封装

**12.2.2 学会如何与GPT交流**

总的来说，我们在与GPT交流时要遵循“ABCD”原则，以更好地驱动大语言模型完成我们所需要的任务。

（1）**准确（Accuracy）**。准确在这里有两个含义。第一个含义是要“明确问题”，以便GPT更好地理解问题并提供有针对性的答案；第二个含义是要“避免歧义”，应避免使用模糊或具有多重含义的语言，以免引起歧义，影响交流效果。

（2）**背景（Background）**。在让GPT模型进行“角色扮演”的情况下，需要提供充足的背景信息，以使GPT了解与用户沟通的方式。除了前文提到的Linux命令行终端的例子，如果我们希望GPT扮演“英语翻译员”的角色，那么需要提供足够的背景信息。

（3）**简洁（Conciseness）**。GPT是一种基于自然语言处理技术的模型，是通过对大量文本数据的学习而得出的模型，因此它具备理解和使用各种不同自然语言表达方式的能力。但是，GPT仍然是一种机器学习模型，无法理解人类思考的复杂性和情感因素。这意味着当与GPT进行交流时，需要使用简洁明了的语言，以便它更好地理解用户的意图。

（4）**分治（Divide-and-Conquer）**。面对复杂问题，人类解决问题的思路往往是先将其进行分解，然后逐步解决，即分而治之。

类似地，大语言模型在处理复杂问题时也会将任务进行拆分，并给出中间的思考过程，这个过程被称为思维链（Chain-of-Thought）。与直接给出“提示语-回答”不同，思维链解决问题的方式是“起始语-思维链-得到结论”。需要注意的是，思维链并不是一种完全自动化的过程，由于它可能受限于模型的先验知识和语言数据，因此在某些情况下可能会出现意外结果。

![image](https://github.com/user-attachments/assets/d235580c-ea72-48c1-aa29-41939b87634f)


这种分治的方法在与GPT进行多轮交互对话时也值得借鉴。尽管GPT-4已经支持32000个token的上下文，远超过了GPT 3.5的4096个token，但依然无法覆盖所有的使用场景。

提示：在文本处理中，我们通常使用预处理技术，将原始文本数据转换成机器学习算法或模型所需的格式。其中，token是预处理后的文本数据中的基本单元，指的是被分割的词语、标点符号、数字等，通常还需要进行标记化和编码等处理，以便机器学习算法或模型能够更好地理解和处理。一般来讲，1个token约等于0.75个英文单词，或者0.4 - 0.5个汉字。

例如，当处理超长文本生成摘要时，首先将文本按章节拆分成多个部分，每个部分都可以分别生成摘要，然后将各部分的摘要合并起来，这样可以降低整个任务的复杂度，也可以更加高效地处理文本数据。

微软开源了一款助力开发大语言模型相关应用的工具的SDK库——Semantic Kernel，在源代码中可以看到许多与提示语相关的配置模板。如果仔细查看，则会发现其中有许多优质的提示语都附带了示例，这有助于大语言模型理解用户的意图。 
