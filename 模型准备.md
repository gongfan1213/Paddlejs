### 第5章 模型准备
一般情况下，Paddle.js已经封装好的paddlejs - models模型库可以满足开发者的需要，但是在涉及新的场景并需要适配新的原始模型时，生产一个可被正确执行的推理模型是一项绕不开的工作。本章将会介绍如何准备推理模型：将原始模型转换为目标推理引擎需要的模型格式，并确保模型中的算子在选定的计算方案中得到支持。

#### 5.1 模型转换
在第3章中介绍过，不同的推理引擎对模型信息的组织方式和模型文件的格式要求有所不同，所以会有模型转换的环节，即将原始模型适配成推理引擎需要的模型组织形式，并保存成文件。
以文件形式保存的模型信息包含两部分内容：神经网络的拓扑结构和权重数据。对Web平台来说，JSON是一种非常友好的信息存储格式，可以用于描述复杂的数据结构。因此，一般前端推理引擎会将神经网络结构信息整合后保存在JSON文件中，并将权重数据保存在二进制文件中。
Paddle.js框架中的paddlejs - converter模块（下文简称为converter）是一个离线转换器，负责整合原始模型信息，并生成包含模型结构信息的model.json文件和包含权重数据的chunk_*.dat文件。
其中，权重数据文件名称中的“*”代表权重数据文件的序号（1,2,3,…），将原始数据按序号分割存储。之所以这样做，是因为当权重数据较多时，以单文件方式存储会带来加载性能问题，所以需要通过数据分片来并行加载数据，converter默认的分片大小为4096KB。
下面仍以converter为例，介绍转换器的使用方法及原理。需要注意的是，此模块是对Paddle格式的原始模型进行转换，若原始模型是其他类型，则需要先使用第3章介绍的X2Paddle工具将目标模型转换成Paddle格式的模型，再使用converter进行模型转换。
提示：JSON（JavaScript Object Notation）是一种轻量级的数据交换格式，容易序列化与反序列化，在JavaScript中可以直接使用。

##### 5.1.1 转换工具使用
converter的转换过程是在离线环境下进行的，转换功能由Python脚本实现，所以先准备好环境依赖再使用。
1. **环境依赖**
环境依赖包括Python版本依赖和Python软件包依赖。
    - **Python版本依赖**：可选Python版本如下。
      - Python 2.7.15+。
      - Python 3.5.1+/ 3.6/ 3.7。
提示：若Python是3.x版本，则可能要将后面执行命令中的Python替换成Python 3。
开发环境可能需要安装多个版本的Python，由于Python项目的依赖包会存在不同的版本，或只支持某些Python版本，因此建议使用Python虚拟环境工具，以避免这种复杂的依赖关系造成的环境冲突。本章以Anaconda工具为例，管理Python虚拟环境，安装及使用方法如下。
第一步，前往Anaconda主页，首先按照官方提示安装对应平台、对应Python版本的Anaconda，然后在终端或命令行中通过一些简单的命令操作虚拟环境。
第二步，创建Python虚拟环境，执行以下代码。
```
conda create --name <your_env_name>
```
第三步，切换至已创建好的虚拟环境，执行以下代码。
```
#在Linux系统或macOS系统下执行
conda activate <your_env_name>
#在Windows系统下执行
activate <your_env_name>
```
    - **Python软件包依赖**：由于converter调用了PaddlePaddle及Paddle Lite软件包，因此需要安装相应依赖，安装方法如下。
      - #如果需要使用优化模型的功能，或不知道是否需要使用这种功能，则需要安装PaddlePaddle和Paddle Lite：
```
python -m pip install paddlepaddle paddlelite==2.10.0 -i https://mirror.baidu.com/pypi/simple
```
      - #如果不需要使用优化模型的功能，则只需要安装PaddlePaddle
```
python -m pip install paddlepaddle -i https://mirror.baidu.com/pypi/simple
```
2. **使用方法**
在完成环境依赖安装后，就可以使用converter进行模型转换了。
    - **方式一**：首先，要确保已经从GitHub克隆了Paddle.js的代码库，进入packages/paddlejs - converter目录，运行convertToPaddleJSModel.py脚本。
Paddle模型的权重数据文件有两种格式，一种为合并参数格式，即模型的全部权重数据都保存到一个文件中；另一种为分片参数格式，此时每个权重分片对应一个文件。
如果希望生成的推理模型为合并参数格式，则可以执行以下命令。
```
python convertToPaddleJSModel.py
--modelPath=<model_file_path>
--paramPath=<param_file_path>
--outputDir=<paddlejs_model_directory>
```
如果希望生成的推理模型为分片参数格式，则可以执行以下命令。
#注意：使用这种方式调用converter需要保证在inputDir中，模型文件名为：__model__
```
python convertToPaddleJSModel.py
--inputDir=<model_directory>
--outputDir=<paddlejs_model_directory>
```
转换成功后，converter会生成模型结构文件model.json及权重数据文件chunk_*.dat。
converter的详细参数描述如下表所示。
|参数|描述|
| ---- | ---- |
| -inputDir | Paddle模型所在目录，当且仅当使用分片参数格式时使用该参数，将忽略-modelPath和-paramPath参数，且模型文件名必须为__model__ |
| -modelPath | Paddle模型文件所在路径，使用合并参数格式时使用该参数 |
| -paramPath | Paddle参数文件所在路径，使用合并参数格式时使用该参数 |
| -outputDir | 必选参数，Paddle.js模型输出路径 |
| -disableOptimize | 是否关闭模型优化，1为关闭优化，0为开启优化(需要安装Paddle Lite)，默认开启优化 |
| -logModelInfo | 是否打印模型结构信息，0为不打印，1为打印，默认为不打印 |
| -sliceDataSize | 当分片输出Paddle.js参数文件时，每片文件的大小，单位为KB，默认值为4096 |
    - **方式二**：可以直接使用Python工具paddlejsconverter进行转换，参数使用情况与方式一中参数使用情况相同，调用命令如下。
```
paddlejsconverter --modelPath=user_model_path
--paramPath=user_model_params_path
--outputDir=model_saved_path
```

##### 5.1.2 转换过程
5.1.1节介绍了如何使用converter，下面详细介绍模型转换的过程，如图5 - 1所示。
![图5-1 模型转换过程](此处因无法直接获取图片内容，无法准确展示，可参考原书对应图片)
1. **模型优化**
模型优化是转换过程中可选的一环，对原始模型进行量化、子图融合、无效算子精简等优化，能够提升模型的推理性能。由于该优化过程涉及原始模型结构的变更，因此一般会放到离线转换的过程中使用。
converter集成了Paddle Lite的opt工具以实现上述优化。下面以子图融合为例，介绍模型优化的过程。
子图融合是多种图优化操作的一种方式，它通过分析模型网络中相关的算子，进行算子重组和融合，以减少算子间的数据传递与调度开销，提高计算资源的利用率，缩短推理时间。
如图5 - 2所示，将conv2d、batch_norm和ReLU三个算子进行重组合并，生成新的融合算子conv2d。
![图5-2 算子融合](此处因无法直接获取图片内容，无法准确展示，可参考原书对应图片)
模型优化完成后，opt工具会生成新的模型文件，以替代原始模型文件。后续转换工作是基于新生成的模型文件进行的。
2. **组织神经网络拓扑结构**
神经网络模型是以计算单元为基本单位组成的，这些计算单元被称为算子（Operator，Op），5.2节会对算子进行更为详细的介绍。对原始模型的网络拓扑结构进行信息提取、适配并保存为新的文件格式，如图5 - 3所示。
![图5-3 网络拓扑结构](此处因无法直接获取图片内容，无法准确展示，可参考原书对应图片)
- 遍历原始模型的网络计算图，获取每个算子的结构信息。
- 以算子为单位，提取推理过程中所必需的信息，包括输入/输出、计算过程依赖的属性，并生成JSON Object。
- 生成以算子为单位的新的网络拓扑结构。
- 将新生成的网络拓扑结构信息写入model.json文件。
3. **权重数据处理**
权重数据是模型在训练阶段通过不断调优训练出来的，在推理阶段会参与到算子的执行过程中，权重数据处理如图5 - 4所示。
![图5-4 权重数据处理](此处因无法直接获取图片内容，无法准确展示，可参考原书对应图片)
- 遍历计算图的算子。
- 将每个算子的所有Tensor对应的权重值加入权重值列表。
- 对权重值按照相应Tensor的名称的字母顺序排序。
- 对排序后的权重值列表数据按照设定的分片阈值进行分片，默认分片阈值为4096KB。
- 将权重数据按分片结果保存成二进制文件。

至此，模型转换完成，转换产物是一个model.json文件和若干个chunk_*.dat二进制权重数据文件。

#### 5.2 模型算子
5.1节中提到，算子是神经网络模型计算的基本单位。本节将进入算子的世界，认识并学习如何开发一个算子，以应对前端推理引擎中选定的计算方案不支持某个算子的情况。

##### 5.2.1 算子基本信息
算子是神经网络的计算单元，每一种算子都对应网络模型中的一种计算逻辑，如卷积层（Convolution Layer）是一种算子，全连接层（Fully - Connected Layer）也是一种算子，在网络模型中的ReLU、Sigmoid等激活函数也是算子。下面以卷积神经网络中最具代表性的算子conv2d为例，讲解算子信息的构成。图5 - 5所示为模型信息在Netron工具上呈现的可视化结果，Netron导入模型后，会在界面上展示出如图5 - 5左侧所示的模型的拓扑结构。选择要查看的算子节点，如单击左侧圈出的conv2d算子节点，算子的类型、依赖的属性、输入/输出等详细信息会以表格的形式显示在界面右侧。
![图5-5 模型信息在Netron工具上呈现的可视化结果](此处因无法直接获取图片内容，无法准确展示，可参考原书对应图片)
算子有以下基本信息。
- **type**：算子的类型，此算子的类型（type）为conv2d。
- **data_format**：算子数据的物理排布方式，在卷积神经网络中，数据通常用四维数组保存，data_format指明了数据排布维度的顺序，常见的data_format为NCHW或NHWC，AnyLayout即默认排布方式为NCHW。以NCHW为例，它的排列顺序为[batch, channels, height, width]，其中N表示数量，可以理解为这批图像有多少张；H和W分别表示高度和宽度，即图像在竖直方向和水平方向的像素数目；C表示通道数，如黑白图像的通道数（C）为1，而RGB彩色图像的通道数（C）为3。
- **算子计算中依赖的属性**，如fuse_relu、groups、dilations、paddings和strides等。 
