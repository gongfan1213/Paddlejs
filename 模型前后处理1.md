### 第6章 模型前后处理
经过第5章的学习与实践，得到了一个转换后的模型可供推理，接下来结合模型的大小、对设备兼容性的要求和对推理性能的要求，为模型选择一个合适的计算方案，就可以进行模型推理了。其中，计算方案的选择会在第8章进行详细的介绍。在推理的前后，有两个不可省略的衔接环节——模型前处理和模型后处理。模型前处理环节负责将输入的数据适配成模型要求的格式，模型后处理环节针对不同的模型，将推理结果进一步处理成“有意义”的数据。

#### 6.1 模型前处理
模型前处理并不是对模型本身进行处理，而是对输入模型的数据进行处理。数据可能是用户上传的一张图像，也可能是用户打开摄像机后在实时视频流中的一张图像，还可能是前一个模型的输出结果。

##### 6.1.1 媒体资源获取
与图像相关的媒体资源，可通过用户上传获取图像文件，也可通过网络实时通信（Web Real-Time Communications，WebRTC）技术获取视频流，下面先分别详细介绍如何获取这两种媒体资源，再进一步说明如何处理获取到的数据。
1. **用户上传图像**
想要在Web页面上获取到用户上传的图像，可在HTML代码中放置一个标签，用户通过单击该标签选择本地图像文件，或选择摄像机模式实时拍摄一张图像，可参考以下代码进行实践。
    - **在HTML代码中放置一个标签并指定接收的文件格式**：
```html
<!-- 可打开系统的文件选择器，选择图像上传。由于accept的指定，移动端会提供拍照和系统文件两种模式 -->
<input type="file" accept="image/*" id="uploadImg">

<!-- 如果在移动端只想支持摄像机拍照模式，屏蔽系统文件的选择，则可以把capture属性设置为一个字符串 -->
<input type="file" accept="image/*" id="uploadImg" capture="camera">

<!-- 想要调起前置摄像头，capture属性设为user -->
<input type="file" accept="image/*" id="uploadImg" capture="user">

<!-- 想要调起后置摄像头，capture属性设为environment -->
<input type="file" accept="image/*" id="uploadImg" capture="environment">
```
    - **在JavaScript代码中，完成文件上传事件的监听及处理，以获取图像内容**：
```javascript
// 获取input DOM元素
const input = document.getElementById('uploadImg');
// 监听上传文件变更的事件，在事件回调中完成图像数据的获取
input.onchange = function () {
    selectImage(this);
};

function selectImage(file) {
    // 判断文件是否存在
    if (!file.files ||!file.files[0]) {
        return;
    }

    // 加载上传的文件
    const reader = new FileReader();
    reader.onload = function (evt) {
        // 构造Image DOM来获取图像文件内容
        const img = new Image();
        // 图像加载完成，可以直接使用img实例
        img.onload = function () {
        };

        if (evt.target && typeof evt.target.result ==='string') {
            img.src = evt.target.result;
        }
    };
    reader.readAsDataURL(file.files[0]);
}
```

2. **WebRTC技术获取视频流**

除了图像的获取，CV模型常使用视频数据作为模型的输入，在Web中可使用WebRTC技术进行视频处理，并使用getUserMedia API从用户摄像头中获取视频流内容。

在HTML代码中添加标签，或者在JavaScript中创建video DOM对象，并将其插入document中。对video设置自动播放属性，以承载视频流内容。
```javascript
// 检测是否存在video DOM，若不存在，则创建
if (!document.getElementById('video')) {
    const vid = document.createElement('video');
    vid.setAttribute('id', 'video');
    vid.setAttribute('playsinline', 'true');
    vid.setAttribute('webkit-playsinline', 'true');
    vid.setAttribute('x-webkit-airplay', 'true');
    vid.setAttribute('preload', 'true');
    vid.setAttribute('autoplay', 'true');
    vid.setAttribute('auto-rotate', 'false');
    // 按需求设置video的宽和高
    vid.setAttribute('width', 640);
    vid.setAttribute('height', 720);
    document.body.appendChild(vid);
}
```

调起摄像头，获取视频流内容，示例代码如下。

```javascript
const videoElement = document.getElementById('video');
videoElement.onloadeddata = () => {
    // video已经在播放摄像头的视频流数据了
};
checkWebrtc();
getUserMedia({
    video: {
        width: 640
    }
}, success, error);

// 检查是否可以使用WebRTC
function checkWebrtc() {
    getUserMedia({
        video: {
            width: 640
        }
    }, () => {}, () => {
        this.cannotRun = true;
        alert('不支持webrtc');
    });
}

// 选择WebRTC能用的API
function getUserMedia(constraints, success, error) {
    if (navigator.mediaDevices.getUserMedia) {
        // 最新的标准API
        navigator.mediaDevices.getUserMedia(constraints).then(success).catch(error);
    } else if (navigator.webkitGetUserMedia) {
        // Webkit核心浏览器
        navigator.webkitGetUserMedia(constraints, success, error);
    } else if (navigator.mozGetUserMedia) {
        // Firefox浏览器
        navigator.mozGetUserMedia(constraints, success, error);
    } else if (navigator.getUserMedia) {
        // 旧版API
        navigator.getUserMedia(constraints, success, error);
    }
}

// WebRTC成功回调
function success(stream) {
    videoElement.srcObject = stream;
    videoElement.play();
}

// WebRTC回调失败
function error() {
    console.log('摄像头获取失败');
}
```
具体步骤如下：
    - 判断是否支持WebRTC。
    - 通过getUserMedia API指定constraints约束。
    - 在成功回调中，把获得的stream赋值给video DOM的srcObject属性。
    - video DOM对象调用play方法，监听video的onloadeddata事件。
    - 在onloadeddata事件回调中，video的内容即当下摄像头内容。video可以设为可见，显示在页面上，也可以进行隐藏，不影响内容的获取。

3. **媒体数据处理**

视频内容的处理与图像的处理一致，常见的处理方式有数据排布转换、裁剪变换等，处理方式会在6.1.2节介绍。视频数据是HTMLVideoElement格式，可在JavaScript中直接获取video对象；图像数据是HTMLImageElement格式，可在JavaScript中获取相应的image对象。这两种格式都

可通过canvas获取像素数据，也可当成在WebGL上下文中的texture。
    - **获取像素数据**：利用canvas，把video或image绘制到canvas画布上，进而获取像素数据。
```javascript
// 创建canvas
const canvas = document.document.createElement('canvas');
// 获取canvas上下文
const cvsctx = canvas.getContext('2d');
// 获取video或image对象，此处以video为例
const video = document.getElementById('video');
// 获取video的宽和高
const videoH = video.height;
const videoW = video.width;
// 对canvas设置宽和高
canvas.height = videoH;
canvas.width = videoW;
// 绘制video数据
cvsctx.drawImage(video, 0, 0);
// 获取canvas画布的像素数据，也是当前视频帧的数据
const videoPixelData = cvsctx.getImageData(0, 0, videoW, videoH);
```
    - **转化为WebGL上下文中的texture**：如果后续的数据处理通过WebGL进行裁剪变换等操作，则可利用WebGL的texImage2D API直接将video或image作为texture来源。texImage2D的接口如下。
```javascript
// WebGL1:
void gl.texImage2D(target, level, internalformat, format, type, HTMLImageElement? pixels);
void gl.texImage2D(target, level, internalformat, format, type, HTMLVideoElement? pixels);
// WebGL2:
void gl.texImage2D(target, level, internalformat, width, height, border, format, type, HTMLImageElement source);
void gl.texImage2D(target, level, internalformat, width, height, border, format, type, HTMLVideoElement source);
```

##### 6.1.2 输入数据处理
6.1.1节提供了图像和视频流两种媒体资源的获取方法，由此可以得到图像与视频的数据，对它们进行适配处理，转换成符合模型要求的输入格式。

常见的输入数据的处理方式有数据排布转换、图像变换、取均值和归一化等。这里重点介绍数据排布转换和图像变换。

1. **数据排布转换**

图像通道是指图像色彩的单色部分，图像的色彩由若干个单色通道共同组成。常见的通道有单通道，即一个像素点用一个数值来表示，单通道只能表示灰度。而在大家熟知的RGB模式中，图像被分解为红、绿、蓝三个通道，所以RGB三通道可以描述彩色图像。进一步地，四通道是在RGB的

基础上添加了alpha通道，用来表示透明度。在CV模型推理时，常用RGB通道模式，通道数为3，接下来以这种通道模式介绍数据排布的转换过程。

第5章介绍过算子数据的物理排布方式，即算子的data_format属性，常见的有NCHW和NHWC两种方式，以此来指明数据排布的维度顺序。

若以一张图像信息作为模型的输入，则该输入的N为1，C为3，H和W分别代表图像的高度和宽度。在媒体数据处理中，canvas与WebGL对图像的处理都是按照[H, W, C]的维度顺序进行的。

当模型要求输入的data_format是NCHW时，需要转换成NCHW的排布，下面用函数nhwc2nchw来实现这一过程。
```javascript
/**
 * @param data 把图像像素数据按照[H, W, C]的维度顺序拉平成一维数组
 * @param shape data的排布方式，图像数据用四维数组表示，模式为[1, h, w, 3]
 * @returns 排布方式从NHWC转换至NCHW的一维数据结果
 */
function nhwc2nchw(data, shape) {
    const [N, H, W, C] = shape;
    const WC = W * C;
    const HWC = H * W * C;
    const nchwData = [];
    for (let n = 0; n < N; n++) {
        for (let c = 0; c < C; c++) {
            for (let h = 0; h < H; h++) {
                for (let w = 0; w < W; w++) {
                    nchwData.push(data[n * HWC + h * WC + w * C + c]);
                }
            }
        }
    }
    return nchwData;
}
```
2. **图像变换**
大部分模型的输入都会有固定的模式（shape）要求，以图像数据作为输入时，要根据目标模式，对图像进行缩放、裁剪和填充等适配。例如，假设模型的输入模式为[1,3,224,224]，而获取到的图像长为1080像素，宽为720像素，就需要把1080像素×720像素的图像装入224像素×224像素的目标区域。要进行的适配过程可能有以下情况。
    - **保留图像的全部信息**：用大家熟知的CSS的background-size属性值来类比，这种情况可类比于contain，即尽可能地缩放图像并保持宽高比，使图像完全显示在目标区域内。 
