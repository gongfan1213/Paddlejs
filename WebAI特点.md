### 1.1 Web AI的特点
Web AI开发的流程大体包括数据收集与处理、模型选取、模型训练、效果评估和模型部署（在本书第3章会详细介绍）。在传统的流程中，模型部署在后端的高性能服务器上，用户端先通过网络将数据传递给服务器，服务器执行推理操作，再通过网络返回给用户端。对于这个流程，读者可以很容易发现其中的缺点。

- 延时高。即便服务端的算力非常强，但是由于网络请求的延时，以及不确定的用户接入时的网络状况，因此对于高实时性和高帧率的应用，这种基于云端部署的解决方案无法满足用户需求，特别是在游戏、AR应用等场景中。
  
- 隐私问题。用户需要把数据上传到服务端，当受到中间人攻击或服务端出现安全问题时，数据中的隐私信息就有可能被攻击者收集。
  
- 灵活性差。因为关键数据通过网络传递，所以需要依赖数据的序列化和反序列化，且因为前后端分离，业务升级导致推理接口的输入和输出变化也很难得到及时响应。
  
- 成本高。对于推理服务高频调用的场景，服务端的模型部署意味着占用更多的带宽资源和耗费更多的服务器计算资源。 

而Web侧的推理预测方案依赖的是训练后的模型文件，通过调用转化为适合浏览器端且调优过的模型，用户端可以自行完成整个推理流程，传统的网络调用变成了用户端的本地调用，数据传输效率和响应速度都有很大的提升。 

但我们要清楚地认识到：Web AI和端AI并不矛盾。事实上，在很多依然需要大量计算的场景中，Web AI经常起到打头阵和补充优化的作用。例如，收集人脸关键点信息并发送给云端以减少传输数据量，或者对服务端返回的Feed流根据用户行为进行重排。总之，应用Web AI只有做到扬长避短，才能在全局范围内发挥AI的潜力。 


ConvNetJS使得深度学习模型的训练可以再浏览器当中执行的，服务于神经网络的前端库LBrain.js,Synaptic,Neataptic,WebDNN,Keras.js等等WebDNN专精于前端推理，并没有涉及模型训练，该框架对DNN模型进行了深入优化，并且只是WebGL，WebGPU，和WebAssembly等计算方案，在浏览器端部署轻量模型并且执行推理产出预测结果是前端深度学习框架的主要任务。

感知机的作用是在n维空间当中创建一个超平面，从而对数据进行分类的

激活函数是一种特殊的算子，是为了给神经网络引入非线性的，激活函数的非线性可以防止神经网络坍缩成单层神经网络。算子是神经网络计算的基本单元，

对于前端引擎来说，最核心的功能就是在浏览器等web环境当中通过模型文件还原神经网络，然后执行推理预测。


paddle Lite是一种高性能，轻量级的，灵活性强的，易于扩展的深度学习推理框架，它定位于支持包括移动端，嵌入式以及服务端在内的多硬件平台。


前端推理引擎的核心就是在浏览器等web环境当中，通过模型文件还原神经网络继而执行推理预测。




