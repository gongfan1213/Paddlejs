### 第8章 计算方案
前端推理引擎根据算子的属性和计算规则，利用不同的技术栈对同一个算子实现了多个版本。不同的版本即前端推理引擎不同的计算方案，它们在设备算力的利用、运算性能和兼容性方面的表现各不相同。

目前，Paddle.js前端推理引擎提供的计算方案有PlainJS、WebGL、WebGPU、WebAssembly和NodeGL。本章将着重介绍各种计算方案的计算原理和兼容性，以及在实际中如何选择合适的计算方案。

#### 8.1 基本概念
第2章曾介绍过，神经网络涉及大量的矩阵与向量加法和乘法计算。以计算机视觉模型为例，可把算子的计算过程看成一张图像的变换过程。在各种参数的作用下，成千上万个像素参与计算，是典型的计算密集型任务，因此计算的并行化尤为重要。

在正式介绍Paddle.js的计算方案之前，本节将介绍一些在并行化计算中涉及的基本概念，以便阐明Paddle.js为并行化计算所进行的一些努力与优化。

##### 8.1.1 多线程
当一段JavaScript程序在Web的单线程中运行时，有一些方式可使程序的运行在浏览器中达到并发的效果。

已经流行多年的Web Worker API可以创建Worker线程，但线程间依赖消息传递进行通信，无法共享数据，所以Web Worker适合粗粒度的并发，在Worker线程中完成相对较大的任务。而一个Web AI应用在模型加载、环境初始化及推理的过程中都会占用JS主线程，造成页面交互卡顿现象。将AI推理移入Web Worker中，可以将应用与推理环境的加载并行执行，并且在推理时不打断用户的交互行为，使AI应用的体验更加流畅。Web Worker在Paddle.js上的应用会在8.2.6节详细介绍。

SharedArrayBuffer和原子操作可以跨多个线程使用共享内存，以实现更细粒度的并发。但由于它们受到Spectre和Meltdown漏洞的威胁，各浏览器厂商停止了对它们的支持。目前，Chrome浏览器提出了通过跨域隔离声明来解决这一问题，Chrome 91版本和FireFox 79版本引入了这一解决方案。

##### 8.1.2 SIMD
单指令多数据流（Single Instruction Multiple Data, SIMD）使用单条指令同时处理多个数据，可以实现数据层面的并行计算。

算子参与运算的数据是多维数组的形式，且具有相同的类型，大部分算子的输出数组中的每个分量的计算过程都是独立的，因而非常适合SIMD这种在多个数据点上执行相同指令的计算机架构。例如，对两个长度为4的数组执行加法计算时，使用SIMD指令计算，如图8-1（b）所示，只需要执行1次向量加法指令即可，而使用如图8-1（a）所示的普通指令计算需要执行4次普通加法指令。

（a）普通指令计算
\[
\begin{align*}
A_x + B_x &= C_x\\
A_y + B_y &= C_y\\
A_z + B_z &= C_z\\
A_w + B_w &= C_w
\end{align*}
\]

（b）SIMD指令计算
\[
\begin{bmatrix}
A_x\\
A_y\\
A_z\\
A_w
\end{bmatrix}
+
\begin{bmatrix}
B_x\\
B_y\\
B_z\\
B_w
\end{bmatrix}
=
\begin{bmatrix}
C_x\\
C_y\\
C_z\\
C_w
\end{bmatrix}
\]

图8-1 普通指令计算与SIMD指令计算

##### 8.1.3 CPU与GPU
中央处理器（Central Processing Unit, CPU）作为计算机系统的“大脑”，负责解释指令、处理数据。

图形处理器（Graphics Processing Unit, GPU）拥有众多的算术逻辑单元（Arithmetic and Logic Unit, ALU），即计算单元，适合处理海量的统一数据，融合了上述介绍的多线程、SIMD些其他并行化方法，是一种多指令多数据流（Multiple Instruction Multiple Data, MIMD）多指令多数据流（Multiple）处理器。

图8-2对CPU与GPU两者的计算方案硬件架构进行了对比，由于GPU拥有众多的计算单元，一些计算量相对较大的模型在推理过程中若使用GPU进行并行计算，那么运算性能将得到极大的提升。而对于一些计算量相对较小的模型，CPU与GPU之间的调度开销超过了计算开销，此时使用CPU进行并行计算会更为合适。在Paddle.js中，目前共有5种计算方案（具体方案详见8.2节），其中，Plain JS和WebAssembly计算方案运用的是CPU算力，而WebGL、WebGPU和NodeGL计算方案运用的是GPU算力。

![image](https://github.com/user-attachments/assets/d5199bf9-6ea0-45e6-9020-2ca5d11872cf)



图8-2 CPU与GPU两者的计算方案硬件架构对比

#### 8.2 计算方案介绍
本节以一个简化的加法算子elementwise_add为例，介绍Paddle.js中各种计算方案的原理和兼容性。

下面先明确elementwise_add算子的定义。如图8-3所示，以a + b = out为例，若a、b和out的模式均相同，则算子的计算逻辑即对应位置的数字相加求和。

![image](https://github.com/user-attachments/assets/1b876c01-9986-4b99-8758-91d5d8a5a96a)



图8-3 简化的elementwise_add算子

##### 8.2.1 PlainJS计算方案
PlainJS是使用JavaScript脚本实现的、运行在CPU中的计算方案。此方案的优点在于，对前端工程师极其友好，算子接入的成本低，前端工程师只需要掌握JavaScript编程即可，调试简单、兼容性好。相对地，PlainJS的缺点也很明显，较其他计算方案性能偏差。因而，PlainJS计算方案适合对兼容性要求极高、对推理时间无要求的小模型。

以简化的elementwise_add算子为例，主要的代码实现逻辑如下，整个实现过程由4层循环完成。
```javascript
/**
 * @param a number[] 被加数
 * @param b number[] 加数
 * @returns number[] 和
 */
function main(x: number[], y: number[], outShape: number[]): number[] {
    // 假设输入a、b和输出out的模式都相同，布局是NCHW，均为四维
    const [N, C, H, W] = outShape;
    const totalShape = N * C * H * W;
    const out = new Array(totalShape);
    const reducedShape = [C * H * W, H * W, W];
    for (let n = 0; n < N; n++) {
        for (let c = 0; c < C; c++) {
            for (let h = 0; h < H; h++) {
                for (let w = 0; w < W; w++) {
                    const index = n * reducedShape[0] + c * reducedShape[1] + h * reducedShape[2] + w;
                    out[index] = x[index] + y[index];
                }
            }
        }
    }
    return out;
}
```

##### 8.2.2 WebGL计算方案
从PlainJS计算方案对elementwise_add算子的实现过程中可以看出，算子的计算过程是可以高度并行化的。若要在Web环境中利用GPU硬件，则可选择WebGL或WebGPU计算方案，WebGPU计算方案将在8.2.3节中介绍，本节主要关注WebGL计算方案。

Web图形库（Web Graphics Library, WebGL）是一种3D绘图协议，被用来在Web浏览器中渲染高性能的交互式3D和2D图形。WebGL有两个版本，1.0版本与OpenGLES 2.0 API一致，2.0版本与OpenGLES 3.0 API一致。WebGL既可以被应用于高性能图形渲染，也可以被应用于高性能并行计算。

WebGL计算方案的推理过程可总结为初始化、创建程序、执行程序和读取结果四个步骤，如图8-4所示。


![image](https://github.com/user-attachments/assets/cac91b5b-8986-43f6-a115-0009ffa3ebd2)


图8-4 WebGL计算方案

1. 在CPU中预先编译好通过WebGL实现的计算程序。WebGL的编程语言是在OpenGL的着色器语言（OpenGL Shading Language, GLSL）的基础上，删除和简化一部分功能后形成的GLSL ES版本，它有顶点着色器（Vertex Shader）和片元着色器（Fragment Shader）两部分。其中，顶点着色器负责对算子数据的索引计算，这一步对所有的算子都是通用的。
2. 算子的计算主程序是通过片元着色器的编写完成的。conv2d算子的片元着色器主要代码如下。
```glsl
function genShaderCode() {
    // elementwise_add算子的模式语言实现
    return `
    // start函数，输入texture_x、texture_y的宽度为width，高度为height，通道数为channel
    void main(float width, float height, float channel) {
        // 获取output的坐标
        vec2 outCoord;
        outCoord.x = vCoord.x * width;
        outCoord.y = vCoord.y * width;
        // 输入Tensor坐标转输出Tensor坐标系
        int r = mod(outCoord.y / channel);
        int g = mod(outCoord.x, height);
        int b = mod(outCoord.y, height);
        int a = int(outCoord.x / channel);

        // 获取texture_x的像素值
        vec4 x = TEXTURE2D(texture_a,
            vec2(
                (float(a * int(channel) + g) + 0.5) / width,
                (float(r * int(height) + b) + 0.5) / height
            )
        );

        // 获取texture_y的像素值
        vec4 y = TEXTURE2D(texture_b,
            vec2(
                (float(a * int(channel) + g) + 0.5) / width,
                (float(r * int(height) + b) + 0.5) / height
            )
        );

        gl_FragColor = x + y;
    }
    `;
}
```
3. 算子计算过程依赖的参数数据需要从CPU内存复制到GPU显存中，在WebGL中，这一步可通过调用texImage2D API进行纹理绑定来完成。
4. 完成推理后，要把计算结果从GPU显存复制回CPU内存中，在WebGL中，这一步可通过调用readPixels API来完成。

经过了以上四个步骤，WebGL计算方案将算子实现的主逻辑运行在GPU中。由于利用了GPU的算力，因此WebGL计算方案适合相对大一些的模型，并且常见的浏览器都支持WebGL，兼容性很好。但由于算子的实现需要编写相应的着色器，对前端工程师来说，着色器并不是常用的编程语言，且不易调试，所以算子的接入成本偏高。

##### 8.2.3 WebGPU计算方案
WebGPU计算方案是利用GPU算力的另一种选择。WebGPU是新一代Web 3D图形API标准，包括图形和计算两方面的接口。与WebGL计算方案相比，WebGPU计算方案和WebGL计算方案都是对GPU功能的抽象，提供了操作GPU的接口。不同的是，WebGL计算方案基于OpenGL，而WebGPU计算方案基于Vulkan、Metal和Direct3D 12，能提供更好的性能、支持多线程、采用面向对象编程的相对较新的引擎，可以把WebGPU看成下一代WebGL，通过以下代码查看运行环境是否支持WebGPU。
```javascript
// navigator上的属性gpu是一个GPU对象，是WebGPU的入口
if ('gpu' in navigator) {
    // 支持WebGPU
}
```

1. 访问GPU
在WebGPU中访问GPU可以通过以下代码。
```javascript
// 获取GPU适配器GPUAdapter，可以是集成的（low-power）或是独立的（high-performance）
const adapter: GPUAdapter = await navigator.gpu.requestAdapter({
    powerPreference: 'high-performance'
});
// 获取device实例
const device: GPUDevice = await adapter.requestDevice();
```
device是adapter的实例，是整个WebGPU的核心，device（GPUDevice接口）所包含的重要的API方法如下。
```javascript
interface GPUDevice {
   ...
    /**
     * Creates a {@link GPUBuffer}.
     * @param descriptor - Description of the {@link GPUBuffer} to create.
     */
    createBuffer(
        descriptor: GPUBufferDescriptor
    ): GPUBuffer;
    /**
     * Creates a {@link GPUTexture}.
     * @param descriptor - Description of the {@link GPUTexture} to create.
     */
    createTexture(
       ...
    ): GPUTexture;
   ...
}
```

### 8.2.3 WebGPU计算方案（续）
```javascript
descriptor: GPUTextureDescriptor
): GPUTexture;
/**
 * Creates a {@link GPUComputePipeline}.
 * @param descriptor - Description of the {@link GPUComputePipeline} to create.
 */
createComputePipeline(
    descriptor: GPUComputePipelineDescriptor
): GPUComputePipeline;
```
更多WebGPU核心API可查看WebGPU标准和@webgpu/types。

#### 2. 推理过程
WebGPU计算方案的推理过程可总结为初始化、创建程序和数据准备、执行程序、读取结果，如图8-5所示。

![image](https://github.com/user-attachments/assets/7351b326-806a-49c5-8c12-d8287be576c9)



**创建着色器程序**：着色器（Shader）是运行在GPU硬件上的程序。WebGL支持顶点着色器、片元着色器，WebGPU支持顶点着色器、片元着色器和计算着色器（Compute Shader）。计算着色器只计算而不绘制三角形。WebGPU backend所有的算子实现均使用计算着色器，elementwise_add算子的着色器主要代码如下。
```wgsl
// compute shader code in WGSL
// 执行运算时，resultMatrix.size.x和resultMatrix.size.y要替换成具体数字
const shaderWGSL = `
struct Matrix {
    size: vec2<f32>;
    numbers: array<f32>;
};
@group(0) @binding(1)
var<storage, read> originMatrix: Matrix;
@group(0) @binding(2)
var<storage, read> counterMatrix: Matrix;
@group(0) @binding(0)
var<storage, write> resultMatrix: Matrix;
@stage(compute)
@workgroup_size(resultMatrix.size.x, resultMatrix.size.y)
fn main(@builtin(global_invocation_id) global_id: vec3<u32>) {
    let resultCell: vec2<u32> = vec2(global_id.x, global_id.y);
    let index: u32 = resultCell.y + resultCell.x * u32(resultMatrix.size.y);
    resultMatrix.numbers[index] = originMatrix.numbers[index] + counterMatrix.numbers[index];
}
`;
```
WGSL（WebGPU着色器语言）是一个全新的着色器语言，它属于静态类型，每个值都有特定类型。WGSL入口函数需要指明stage，如果是计算着色器，则需要指明workgroup_size。

通过调用device的createShaderModule方法创建shader模块，主要代码如下。
```javascript
interface GPUShaderModule extends GPUObjectBase {
    /**
     * Nominal type branding.
     * @internal
     */
    readonly __brand: "GPUShaderModule";
    /**
     * Returns any messages generated during the {@link GPUShaderModule}'s compilation.
     */
    compilationInfo(): Promise<GPUCompilationInfo>;
}
const shaderModule: GPUShaderModule = device.createShaderModule({
    code: shaderWGSL
});
```

**创建数据缓冲**：在模型执行过程中，总共创建三种GPU数据缓冲区：GPUBufferUsage.STORAGE、GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC、GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ。

 
 - 第一种数据缓冲区用来存储和检索数据。

 - 第二种数据缓冲区用来存储算子计算结果；由于所有GPU队列命令执行完毕后，计算结果需要被复制到另一个数据缓冲区进行读取，所以同时标记了GPUBufferUsage.COPY_SRC。 

 - 第三种数据缓冲区作为最后的数据缓冲区来复制计算结果和数据读取，标记为GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ。

目前，WebGPU还是一种新兴技术，前端工程师可能还需要一段时间才能将其大规模用于生产环境。在Chrome 113版本及以上，可以在设置中打开WebGPU的启用开关，当下一些大语言模型前端库，如Web LLM，就是依赖WebGPU进行推理加速的。

### 8.2.4 WebAssembly计算方案
虽然将推理过程在GPU上执行能够显著提高推理速度，但WebAssembly计算方案有两方面的耗时较长，一是数据初始化，二是数据复制。

 - **数据初始化**：模型的权重数据量很大，WebGL与WebGPU计算方案在数据初始化阶段，会将每个权重数据映射到纹理，这个过程的耗时很长，因而这两种计算方案都有“预热”过程，将数据全部绑定到纹理并完成算子Shader程序的编译工作。用户会有推理速度很快但是加载速度很慢的感觉。 

 - **数据复制**：与GPU相关的计算方案涉及初始化时，从CPU复制数据向GPU传递，以及推理结束读取结果时，从GPU复制数据向CPU传递。

基于这两方面的耗时考虑，当模型比较小，或者AI应用无法接受很长的加载时间时，可以考虑CPU推理方案。而与PlainJS相比，WebAssembly计算方案的推理性能要好得多。

WebAssembly是一个可移植、体积小、加载快且兼容Web的全新二进制格式，有以下几个特点。


 - **高效**：WebAssembly因其二进制格式而体积小、加载快，能够充分发挥硬件能力以达到原生执行效率。 

 - **安全**：WebAssembly执行在沙箱化的环境中，遵守同源策略和浏览器安全策略。 
 
 - **开放**：WebAssembly的文本格式可用来调试、测试与编程。 
 
 - **标准**：WebAssembly具有跨平台属性，无版本、特性可测且向后兼容。 

基于以上特点，将模型的推理过程编译成WebAssembly能够获得更好的推理性能。另外，WebAssembly计算方案可利用多线程和SIMD提升运算性能。
 - **多线程**：WebAssembly是处理计算密集型任务的理想技术，通过多线程可将这些任务分配到多个CPU上执行。多线程依赖共享内存、原子操作和wait/notify操作，依赖SharedArrayBuffer的支持。可在Chrome 70+版本启用实验性WebAssembly的线程支持，或者直接在Chrome 91+版本上体验。 
 - **SIMD**：WebAssembly对各种CPU的SIMD指令进行了抽象，通过变量类型v128及其一系列运算符，让单条指令同时处理多个数据，极大地提高了算子的推理性能。Chrome 91+版本默认开启了WebAssembly的SIMD功能。 

### 8.2.5 NodeGL计算方案
Paddle.js前端推理框架提供了服务端推理的能力——NodeGL计算方案。NodeGL计算方案引入了headless-gl工具包，通过node-gyp可以在Node环境中运行WebGL而不需要启动整个浏览器窗口。目前，NodeGL计算方案只支持WebGL 1.0版本。

WebGL与NodeGL这两种计算方案只有GL的上下文不同，其余实现逻辑完全相同，这里不再赘述。

### 8.2.6 Web Worker在Paddle.js上的应用
GPU的计算方案可以使算子的运算过程并行化，如Paddle.js的WebGL计算方案。但WebGL计算方案也有不足，它需要一个“预热”过程，其中，将权重数据作为纹理的像素源从CPU传至GPU的过程耗时较长。在“预热”期间，应用会受到阻塞，通常的解决办法是通过类似于“加载中”的提示让用户知晓。如图8-6所示，将AI应用推理计算方案的环境初始化和推理过程移到Web Worker中，在初始化阶段，可将推理引擎的初始化与应用的其他初始化内容并行起来，既减少了应用整体的初始化耗时，也不影响用户与页面的交互；在推理阶段，模型推理依赖的数据在JS主线程中处理，模型推理在Worker中进行，既减少了整体的模型推理耗时，也不会阻塞页面对用户操作的响应。

![image](https://github.com/user-attachments/assets/f418aea7-f70c-4002-9d39-7fd912413a36)



**图8-6 Web Worker在WebGL计算方案上的应用**
 
 - **JS主线程**：应用页面加载（静态资源加载、页面渲染），然后进行图像数据处理，接着推理，最后推理结果展示。
 
 - **Worker线程**：推理引擎初始化、模型加载、预热，然后接收JS主线程处理后的图像数据进行推理，将推理结果返回给JS主线程展示。

应用Web Worker进行推理的前提是设备支持OffscreenCanvas，即离屏canvas。离屏canvas的渲染与DOM完全解耦，可以在Web Worker中运行。以1000种物品分类模型的应用为例，介绍它与Web Worker如何结合。

**在Worker线程中运行的worker.js示例如下**
```javascript
import { Runner, env } from '@paddlejs/paddlejs-core';
import { GLHelper } from '@paddlejs/paddlejs-backend-webgl';
// 1000种物品分类模型的序号与类别的映射表
import map from './map.json';
const webWorker = self;
const WEBGL_ATTRIBUTES = {
    alpha: false,
    antialias: false,
    premultipliedAlpha: false,
    preserveDrawingBuffer: false,
    depth: false,
    stencil: false,
    failIfMajorPerformanceCaveat: true,
    powerPreference: 'high-performance'
};
let runner = null;

// 接收JS主线程传递的消息
webWorker.addEventListener('message', async msg => {
    const {
        event,
        data
    } = msg.data;

    // 事件为init，推理引擎初始化；predict为推理，数据类型为ImageData
    switch (event) {
        case 'init':
            await initEvent(data);
            break;
        case 'predict':
            await predictEvent(data);
            break;
        default:
            break;
    }
});

async function initEvent(config) {
    await init(config);
}

async function init(config) {
    const offscreenCanvasFor2D = new OffscreenCanvas(1, 1);
    // 重置Paddle.js引擎core模块mediaprocessor中的canvas
    env.set('canvas2d', offscreenCanvasFor2D);
    // 重置Paddle.js的fetch接口
    env.set('fetch', (path, params) => {
        return new Promise(function (resolve) {
            fetch(path, {
                method: 'get',
                headers: params
            }).then(response => {
                if (params.type === 'arrayBuffer') {
                    return response.arrayBuffer();
                }
                return response.json();
            }).then(data => resolve(data));
        });
    });
    runner = new Runner(config);
    const offscreenCanvas = new OffscreenCanvas(1, 1);
    const gl = offscreenCanvas.getContext('webgl2', WEBGL_ATTRIBUTES);
    // 设置gl Context
    GLHelper.setWebGLRenderingContext(gl);
    // 设置gl Version
    GLHelper.setWebglVersion(2);
    await runner.init();
    // 给JS主线程发送初始化完成的消息
    webWorker.postMessage({
        event: 'init'
    });
}

async function predictEvent(imageBitmap) {
    // 调用Paddle.js推理API
    const res = await runner.predict(imageBitmap);
    // 处理推理结果，此处1000种物品识别案例需要获取数组中的最大值索引，在Map中找到对应的分类
    const maxItem = getMaxItem(res);
    // 给JS主线程发送推理结果
    webWorker.postMessage({
        event: 'predict',
        data: map[maxItem]
    });
}

// 获取数组中的最大值索引
function getMaxItem(datas = []) {
    const max = Math.max.apply(null, datas);
    const index = datas.indexOf(max);
    return index;
}
```

**在JS主线程中执行**
```javascript
const worker = new Worker('worker.js');
// 用于上传图像的DOM，此处为input控件
const uploadDom = document.querySelector('#uploadImg');
// 建立JS主线程与Worker线程的通信
registerWorkerListeners();
// 应用初始化
init();
// 获取用户上传的图像 
```


### 在JS主线程中执行（续）
```javascript
uploadDom.onchange = e => {
    if (!e.target) {
        return;
    }
    const reader = new FileReader();
    reader.onload = () => {
        const img = new Image();
        img.src = URL.createObjectURL((e.target).files[0]);
        img.onload = () => {
            // 加载图像后，获取对应的ImageData数据
            createImageBitmap(img, 0, 0, img.naturalWidth, img.naturalHeight)
           .then(imageBitmap => {
                // 给Worker线程发送predict事件，触发推理
                worker.postMessage({
                    event: 'predict',
                    data: imageBitmap
                }, [imageBitmap]);
            });
        };
    };
    reader.readAsDataURL(e.target.files[0]);
};

function registerWorkerListeners() {
    // 接收Worker线程发送的事件，init表示推理引擎初始化完成，predict表示推理完成
    worker.addEventListener('message', async msg => {
        const {
            event,
            data
        } = msg.data;
        switch (event) {
            case 'predict':
                resultDom.innerText = data;
                break;
            case 'init':
                createImageBitmap(img, 0, 0, img.naturalWidth, img.naturalHeight)
               .then(ImageBitmap => {
                    // 给Worker线程发送推理数据，触发推理
                    worker.postMessage({
                        event: 'predict',
                        data: ImageBitmap
                    }, [ImageBitmap]);
                });
                break;
            default:
                break;
        }
    });
}

async function init() {
    // 检测环境是否支持离屏canvas
    const onscreen = document.createElement('canvas');
    const offscreen = onscreen.transferControlToOffscreen();
    if (offscreen) {
        // 给Worker线程发送init信息，触发推理引擎初始化
        worker.postMessage({
            event: 'init',
            data: {
                modelPath: 'https://paddlejs.cdn.bcebos.com/models/mobileNetV2opt/model.json',
                fill: '#fff',
                feedShape: {
                    fw: 224,
                    fh: 224
                },
                mean: [0.485, 0.456, 0.406],
                std: [0.229, 0.224, 0.225]
            }
        });
    }
}
```

### 8.3 计算方案对比
8.2节详细介绍了各种计算方案的实现原理与兼容性。如表8-1所示，从推理耗时和兼容性两个方面，对PlainJS、WebGL、WebGPU、WebAssembly和NodeGL计算方案进行了详细的对比，其中耗时数据来自MacBook Pro（16inch，2019）设备对MobileNetV2模型的测量。

**表8-1 计算方案对比**
| 计算方案 | 推理耗时/ms | 兼容性 |
| ---- | ---- | ---- |
| PlainJS | 2310 | 所有浏览器 |
| WebGL | 78 | 主流浏览器 |
| WebGPU | 43 | 实验性 |
| WebAssembly | 210 | 基本能力：Chrome 57版本、safari11版本、WebViewAndroid57版本、safari(ios)11版本<br> SIMD和多线程：Chrome 91版本 |
| NodeGL | 70 | 服务端 |

### 8.4 总结
结合多线程、SIMD等并行化计算方法，考虑模型大小、兼容性要求、推理速度和加载速度等因素，Paddle.js前端推理引擎目前提供了PlainJS、WebGL、WebGPU、WebAssembly和NodeGL 5种计算方案。

按照算力的不同，WebGL、WebGPU和NodeGL计算方案运用了GPU的算力，推理速度更快，但需要较长的初始化时间和CPU与GPU间的数据复制时间。PlainJS和WebAssembly计算方案运用CPU的算力，相比之下，PlainJS计算方案兼容性更好，任何可运行JavaScript脚本的环境都支持PlainJS计算方案。而WebAssembly计算方案基于二进制格式，推理速度更快，并且可在Chrome 91版本体验其利用多线程和SIMD提升推理性能的优势。 



